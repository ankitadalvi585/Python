{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjK5MNEkUhQg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load Dataset\n",
        "(train_images,train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "metadata": {
        "id": "JUzR7G7pVgPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_images.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmpV2s29XWUn",
        "outputId": "1716913f-e7da-44e0-cddb-cb6a09ab05a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalize images to be in between 0 & 1 and reshape them\n",
        "train_images = train_images.astype('float32')/255.0\n",
        "test_images = test_images.astype('float32')/255.0\n",
        "train_images = train_images.reshape(train_images.shape[0],28,28,1)\n",
        "test_images = test_images.reshape(test_images.shape[0],28,28,1)"
      ],
      "metadata": {
        "id": "zqrrn9FEVyIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_images.shape)\n",
        "#1 > gray scale > 1 channel\n",
        "# convolution requires the number of channels hence we reshape\n",
        "# for an RGB image the channels are 3 hence channel will be 3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kROen7VwW1SR",
        "outputId": "934b4aa1-a57c-4689-e6e1-825c379c8416"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert labels to one hot encoded format\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "#to_categorical > converts in to integer labels"
      ],
      "metadata": {
        "id": "ffvzK7HnXLG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Buliding the CNN model\n",
        "#Instantiating the Sequential model\n",
        "\n",
        "model= Sequential()\n",
        "\n",
        "#Add layers one by one\n",
        "#Parameters >   Weights > learnable\n",
        "#Hyperparameters are not learnable > its defined based on experiments\n",
        "#(3,3) filter - learnable\n",
        "#By default stride=1\n",
        "model.add(Conv2D(32,(3,3),activation = 'relu',input_shape=(28,28,1),padding='same')) #input shape for 1 image #Convolution Layer\n",
        "model.add(MaxPooling2D((2,2))) #Maxpooling layer filters/parameters > (2,2) kernel size #Not learnable > max in the pool\n",
        "model.add(Conv2D(64,(3,3),activation='relu'))#conv layer with 64 fiters of (3,3) size\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Flatten()) # Flatten > to convert to 1D; done before feeding in to fully connected layer\n",
        "model.add(Dense(128,activation='relu'))#no of neurons 128\n",
        "model.add(Dropout(0.5)) #Half of the neurons get dropped randomly as 0.5 dropout > dropout is done to avoid overfitting and make the model simpler\n",
        "#There's only one hidden layer in this network\n",
        "model.add(Dense(10,activation='softmax'))#op layer > softmax is usually used in op layer if the op is non-binary\n",
        "#If op is binary we use Sigmoid"
      ],
      "metadata": {
        "id": "1ySqIvE0YixL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In regression there is no activation function > we use activation function in case of non-continuous cases"
      ],
      "metadata": {
        "id": "rJZALYfvctxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Compiling the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "#We are using adam optimizer > adaptive, loss function, we use metrics as accuracy (Whatever predicted correctly divided by total)"
      ],
      "metadata": {
        "id": "ty2n48ZEcG17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the model #epoch > 1 iteration through entire dataset\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=32)\n",
        "#Time around 27ms per epoch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQzGrTEYdJrQ",
        "outputId": "a2d8f941-36a9-4f25-94af-d5ceaa802b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 61s 32ms/step - loss: 0.2049 - accuracy: 0.9378\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 59s 31ms/step - loss: 0.0748 - accuracy: 0.9779\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 60s 32ms/step - loss: 0.0556 - accuracy: 0.9827\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 57s 31ms/step - loss: 0.0452 - accuracy: 0.9861\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 59s 31ms/step - loss: 0.0363 - accuracy: 0.9889\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7fb8bde45420>"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the trained model\n",
        "model.save('mnist_cnn_model.keras')"
      ],
      "metadata": {
        "id": "CtOs52lBd61M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "print(f'Test accuracy: {test_accuracy}')\n",
        "print(f'Test loss: {test_loss}')\n",
        "\n",
        "#Accuracy = 99.21%, Loss = 0.024956, 27ms per epoch\n",
        "#On adding stride =2, accuracy decreases to 97.76 and training time decreases to 7ms per epoch\n",
        "#On adding stride=2 and padding as same > training time increases comparatively to 10ms per epoch accuracy increases comparatively to 98.68%\n",
        "#On adding above and changing the filter to 5*5, accuracy increases to 99% , training time 13ms per epoch\n",
        "#On adding above and changing the filter to 7*7, accuracy increases to 98.91% , training time 20ms per epoch\n",
        "\n",
        "#On removing the strides and the padding, and adding filter 7*7, training time~70ms per epoch; accuracy=98.83%\n",
        "#On removing the strides and the padding, and adding filter 5*5, training time~65ms per epoch; accuracy=99.29%\n",
        "#On adding padding with filter 3*3, accuracy = 99.29%, training time ~ 59ms\n",
        "\n",
        "#3*3 on first conv and 5*5 on the next one ....accuracy increased from frst one\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PhmdNs4Vf0rv",
        "outputId": "55cb124b-12b7-4067-92d4-1b5d3c680055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 3s 9ms/step - loss: 0.0223 - accuracy: 0.9929\n",
            "Test accuracy: 0.992900013923645\n",
            "Test loss: 0.02228955179452896\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "kT2hWxeoixhQ",
        "outputId": "c4735e67-6b1b-4310-b743-cdb23e0b26f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a86e5f36-1e6b-4b18-8934-589d98d7c899\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a86e5f36-1e6b-4b18-8934-589d98d7c899\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Number4_Image.png to Number4_Image (1).png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "# Process the uploaded image\n",
        "for fn in uploaded.keys():\n",
        "    # Read, preprocess and display image\n",
        "    path = '/content/' + fn\n",
        "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    img_resized = cv2.resize(img, (28, 28))\n",
        "    plt.imshow(img_resized, cmap='gray')\n",
        "    plt.show()\n",
        "\n",
        "    # Preprocess the image for the model\n",
        "    img_normalized = img_resized / 255.0\n",
        "    if img_normalized[14, 14] > 0.5:  # Check the center pixel & invert if needed\n",
        "        img_normalized = 1.0 - img_normalized\n",
        "    img_normalized = np.expand_dims(img_normalized, axis=0)\n",
        "    img_normalized = np.expand_dims(img_normalized, axis=-1)\n",
        "\n",
        "    # Load the saved CNN model and predict\n",
        "    loaded_model = load_model('mnist_cnn_model.keras')\n",
        "    prediction = loaded_model.predict(img_normalized)\n",
        "    predicted_label = np.argmax(prediction)\n",
        "\n",
        "    print(f\"Predicted Label: {predicted_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "0-hkiRY2kAMN",
        "outputId": "eb752ed4-aad1-422c-9cf2-c3ebc6acf684"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAh1UlEQVR4nO3df2xV9f3H8Vd/Xgq0xQL9JQULKjgR3Jh0DcpwNECXOFFi/PUHGIMRixkwp+miotuSTlyc0TH8Z4OZiCKLwCQbRsGWOIGFKiHG2QDpBoS2IK69pUBb2vP9g9B9K7/6+XDved+W5yO5Cb33vHve93PPva9e7r3vmxQEQSAAAEKWbN0AAODqRAABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADARKp1A9/W3d2tI0eOKDMzU0lJSdbtAAAcBUGg1tZWFRYWKjn54s9zEi6Ajhw5oqKiIus2AABX6NChQxo1atRFL0+4AMrMzJQk1dfXKysry7ibC+vu7rZu4aIG4mSllJSU0Pblc9te6i+8i/G5TmH15ius+0VXV1co+/EV1vEa5n3d9X+jotGorrvuup7H84uJWwCtXLlSL7/8shobGzV58mS9/vrrmjp16mXrzl3RrKwsAsgDAXRlCCB/BNBZBFDf6+JydK5bt07Lli3T8uXL9dlnn2ny5MmaPXu2jh49Go/dAQD6obgE0CuvvKKFCxfqkUce0Xe+8x298cYbGjx4sP70pz/FY3cAgH4o5gHU0dGh2tpalZWV/W8nyckqKyvTjh07ztu+vb1d0Wi01wkAMPDFPIC+/vprdXV1KS8vr9f5eXl5amxsPG/7qqoqZWdn95x4BxwAXB3MP4haWVmplpaWntOhQ4esWwIAhCDm74IbMWKEUlJS1NTU1Ov8pqYm5efnn7d9JBJRJBKJdRsAgAQX82dA6enpmjJlirZu3dpzXnd3t7Zu3arS0tJY7w4A0E/F5XNAy5Yt0/z58/X9739fU6dO1auvvqq2tjY98sgj8dgdAKAfiksA3X///Tp27Jief/55NTY26tZbb9WWLVvOe2MCAODqlRQk2Efno9GosrOzdezYMadJCGlpaXHs6sr5fHrb55PlPjfnQBz66jsBYKBNuUhN9fsb02dfibx2YQpz+kSiikajGj58uFpaWi75OM5KAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMBGXadixkJaW5jRgNMxBiD7DBlNSUkKp6ezsdK7xGZQqhTf4NMzhjok8SNLndvK9Pj778jkefI5xn/t6It+uVzNuFQCACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACAiYSdht3d3R3qhOtEFNb195lILPlNGPaZsuwzQXsgSk11v7v6HkM++wprsrXLlPwr2Y/kd4yHNa3b9zr5Tr930dfeeAYEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADARMIOIw2CQEEQ9Hl7nwF7vkM4wxjmJ/kN4fQZatjZ2elcI8np9jnH5zr57Md3UKPvMRGGM2fOONd88803cegkdjIzM51rhgwZ4lzje7v6HHs+fO6Dvr2FMSy1r73xDAgAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJhB1G2tXV5TT002fAXpgDK30GB6amut88PtfJd1Cjz+BTHz79+d62PtfJZzjtqVOnnGuWLl3qXLNu3TrnGklKT0/3qnP13e9+17nmL3/5i3PN4MGDnWskv9s2rCG9vvc/nzrX/vq6Pc+AAAAmCCAAgImYB9ALL7ygpKSkXqcJEybEejcAgH4uLq8B3Xzzzfroo4/+txOP1zIAAANbXJIhNTVV+fn58fjVAIABIi6vAe3bt0+FhYUaO3asHn74YR08ePCi27a3tysajfY6AQAGvpgHUElJidasWaMtW7Zo1apVqq+v1x133KHW1tYLbl9VVaXs7OyeU1FRUaxbAgAkoJgHUHl5ue677z5NmjRJs2fP1t/+9jc1Nzfr3XffveD2lZWVamlp6TkdOnQo1i0BABJQ3N8dMGzYMN14443av3//BS+PRCKKRCLxbgMAkGDi/jmgEydO6MCBAyooKIj3rgAA/UjMA+ipp55STU2N/v3vf+vTTz/VPffco5SUFD344IOx3hUAoB+L+X/BHT58WA8++KCOHz+ukSNH6vbbb9fOnTs1cuTIWO8KANCPxTyA3nnnnVj/yrjxGTQo+Q3H9Bk26DPU0HewaCLzvZ18dHR0hLKf3//+9841f/3rX51rOjs7nWsk6fTp0841gwYNcq756quvnGt8biPfYaQ+96ewhvSGyXe47+UMvJUCAPQLBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATMT9C+l8dXZ2Og1S9BkaGObgTp99+QwjDXNwp09/PsIa5Cr5rZ/P4M7Nmzc714R52/ocrz6DT9PS0pxrfNbBd0Coz7E3ELmuX1+35xkQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMBEwk7DTk5OdprAGtZkZkk6c+ZMKDVhTevu7u72qgtzmnhYXnrpJeea6dOnx6GT8/ms95AhQ7z21dbW5lzjM9na59g7depUKPuRwn1cCYvPhG/faeKX/b1x+a0AAFwGAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwk7jDQ1NVWpqX1vr6OjI47d9OYzdLGzs9O5xmeAos/ASt+homENavTp77e//a3Xvl555RXnmtLSUueakydPOtdkZ2c71zQ2NjrXSNKgQYO86sLw3//+17nm2muv9dqXz+DOsO4XPr35cn0s6uv2PAMCAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgImGHkSYnJys5ue/5mJGR4bwP3wGmPkMAXa7LOV1dXc41Z86cca7x5XOdfKxdu9a5prKy0mtfLgNwz/EZLOoznDYnJ8e55tChQ841knT69GnnGp8Bpj7HuM9QVt+Buz4DgcMS1tBTH33tjWdAAAATBBAAwIRzAG3fvl133XWXCgsLlZSUpI0bN/a6PAgCPf/88yooKFBGRobKysq0b9++WPULABggnAOora1NkydP1sqVKy94+YoVK/Taa6/pjTfe0K5duzRkyBDNnj3b6/+UAQADl/MrruXl5SovL7/gZUEQ6NVXX9Wzzz6ru+++W5L05ptvKi8vTxs3btQDDzxwZd0CAAaMmL4GVF9fr8bGRpWVlfWcl52drZKSEu3YseOCNe3t7YpGo71OAICBL6YBdO775/Py8nqdn5eXd9Hvpq+qqlJ2dnbPqaioKJYtAQASlPm74CorK9XS0tJz8v3cAgCgf4lpAOXn50uSmpqaep3f1NTUc9m3RSIRZWVl9ToBAAa+mAZQcXGx8vPztXXr1p7zotGodu3apdLS0ljuCgDQzzm/C+7EiRPav39/z8/19fXas2ePcnJyNHr0aC1ZskS//vWvdcMNN6i4uFjPPfecCgsLNXfu3Fj2DQDo55wDaPfu3brzzjt7fl62bJkkaf78+VqzZo2efvpptbW16bHHHlNzc7Nuv/12bdmyxWtOFABg4EoKEmyiXTQaVXZ2thoaGhL29SCfwYY+A0x9BjX63Jy+Axd91uH///dsXz344IPONWFav369c826deucax566CHnmvvuu8+5RvIbRupzvA4ZMsS55tNPP3WuGT9+vHNNmHzWzqdG8nuMcH38ikajys/PV0tLyyUfx83fBQcAuDoRQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEw4fx1DWFJSUrymLYfBZ7K1j+Rk978PfCZbp6enO9dIUm1trXPNwoULvfYVlqFDhzrXZGRkONesXLnSuaaurs65ZsyYMc41krR3717nmtRU94cTn2PPp8Z36H9Y93UfPo8Pkv/0+3jgGRAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATCTuMNCkpyWkQoO+wQR9dXV2h7SsMX375pVfdk08+GeNOLsxn+KTvbeSzr3HjxjnX+Aza7ezsdK45c+aMc40kRSIR55q0tDTnGp/1PnHihHONL5/HFZ8Bpj6DRX0HpfrcN1zXoa/Xh2dAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATCTsMFJXA21AqOQ3bPDYsWPONU899ZRzjSQdPHjQuebUqVPONUOHDnWuyc/Pd66RpJUrVzrXDB8+3LnG53jt6OhwrmlpaXGukcK7P/kMMG1vb3euCfPxwWfQrI8wBzC7Phb1dXueAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADCRsMNIu7q64j5A0GfYpxTeEMDm5mbnmieeeMK55sCBA841kt9wzPT0dOea3Nxc55pXX33VuUaSbr31Vq86Vz7Hns/aZWRkONdI4Q3U9NHW1uZc093d7bWv5GT3v9E7OztD2Y/v45fPvuK1D54BAQBMEEAAABPOAbR9+3bdddddKiwsVFJSkjZu3Njr8gULFigpKanXac6cObHqFwAwQDgHUFtbmyZPnnzJL+6aM2eOGhoaek5vv/32FTUJABh4nN+EUF5ervLy8ktuE4lEvL+REgBwdYjLa0DV1dXKzc3V+PHjtWjRIh0/fvyi27a3tysajfY6AQAGvpgH0Jw5c/Tmm29q69ateumll1RTU6Py8vKLvqW6qqpK2dnZPaeioqJYtwQASEAx/xzQAw880PPvW265RZMmTdK4ceNUXV2tmTNnnrd9ZWWlli1b1vNzNBolhADgKhD3t2GPHTtWI0aM0P79+y94eSQSUVZWVq8TAGDgi3sAHT58WMePH1dBQUG8dwUA6Eec/wvuxIkTvZ7N1NfXa8+ePcrJyVFOTo5efPFFzZs3T/n5+Tpw4ICefvppXX/99Zo9e3ZMGwcA9G/OAbR7927deeedPT+fe/1m/vz5WrVqlfbu3as///nPam5uVmFhoWbNmqVf/epXikQisesaANDvOQfQjBkzLjmM84MPPriihnz5DE/0HXbqM9iwvb3duWb+/PnONbW1tc41PsMdJSktLc25xud28hmweuONNzrXSFJLS4tzTWZmpnNNQ0ODc83hw4eda7755hvnGsnvvjFo0CDnGp/7ks+A1TNnzjjXSH7Hq8+QUJ918B0qGu8hzy77YBYcAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMBEUnCp0dYGotGosrOzdezYMadvR/WZWut71Ts7O51r9u3b51wzbdo05xqfdfCpkfym6vrsy+fLDH0mdUtSY2Ojc011dbVzzR133OFcc+rUKeea06dPO9dI0pAhQ7zqXPn05/Otyenp6c41kvSTn/zEuWbFihVe+3Lle7/14Tp5OxqNKjc3Vy0tLZe8vXgGBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwESqdQOxkmAzVc/T1NTkXJORkeFc09HR4VzjM1RU8hvw6DNA8ejRo841YV4nn8GnPoNFffgOFfVdP1dhrV00GnWukaTm5mavOlc+j19h3UaSe3997Y1nQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwk7DDSIAgSdsCoz0DN9vb2UPbjM0zTd6ihz+DTa665xrkmNdX9MPUd9umz5j79hTXI1XcdfPrzOR46OzudawYNGuRc43N9JL/bNjnZ/e/6MAeL+nDtj2GkAICERgABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwETCDiPt6uqK+4A+n+GOkt+wwdtvv9255oMPPnCu8eEzEFKSWltbnWt8hjv68L1tfep8Bqxu3rzZuWbPnj3ONZWVlc41kt9gUd81d/Xcc88515SWlnrty2eIaVJSknONz9r57Efye/xy1dd14xkQAMAEAQQAMOEUQFVVVbrtttuUmZmp3NxczZ07V3V1db22OX36tCoqKjR8+HANHTpU8+bNU1NTU0ybBgD0f04BVFNTo4qKCu3cuVMffvihOjs7NWvWLLW1tfVss3TpUr3//vtav369ampqdOTIEd17770xbxwA0L85vSK8ZcuWXj+vWbNGubm5qq2t1fTp09XS0qI//vGPWrt2rX70ox9JklavXq2bbrpJO3fu1A9+8IPYdQ4A6Neu6DWglpYWSVJOTo4kqba2Vp2dnSorK+vZZsKECRo9erR27Nhxwd/R3t6uaDTa6wQAGPi8A6i7u1tLlizRtGnTNHHiRElSY2Oj0tPTNWzYsF7b5uXlqbGx8YK/p6qqStnZ2T2noqIi35YAAP2IdwBVVFToiy++0DvvvHNFDVRWVqqlpaXndOjQoSv6fQCA/sHrU4GLFy/W5s2btX37do0aNarn/Pz8fHV0dKi5ubnXs6Cmpibl5+df8HdFIhFFIhGfNgAA/ZjTM6AgCLR48WJt2LBB27ZtU3Fxca/Lp0yZorS0NG3durXnvLq6Oh08eND7k8gAgIHJ6RlQRUWF1q5dq02bNikzM7PndZ3s7GxlZGQoOztbjz76qJYtW6acnBxlZWXpySefVGlpKe+AAwD04hRAq1atkiTNmDGj1/mrV6/WggULJEm/+93vlJycrHnz5qm9vV2zZ8/WH/7wh5g0CwAYOJwCKAiCy24zaNAgrVy5UitXrvRuykd3d7dzje9gzL6sw7cNHTrUuWb8+PHONT7r4Dv01WcdfPhcJ18+wyd9hjveeuutzjU+A0JPnz7tXCOdvR+78jmOfAbh+txvJ02a5Fwj+d22Yd0vfIXxGNHX25VZcAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAE37joEOQlJSkpKSkPm/vM7U20aWkpISyH9/pvT5TdX325VPjcuxc6b7CkpWV5VwzZMgQr335Tkh3lZaW5lzjc7/wfXzwOcbDeizyPVZ97huu16mv2w+8R20AQL9AAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADARMIOI01JSXEaOpjIQyQlvwGAYQ3h9B3c6TMU8syZM6Hsx3eYps/wybCGY44cOdK5prS01LlGklJT3R8aBg0a5FwTjUada2666SbnGl8+t63P/dbnePW93/oMgHW9X/S1N54BAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMJGww0hPnDjhNLDRZxCiL98hgK7CGrDqMxhT8hvc6bN2YQ5q9NlXWAMrc3JynGveffdd5xopsY9xn/X2OVbD5LPeYd5vXW+nvm7PMyAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmEnYYqaswhw2mprovW1hDLn349Cb5D0NMZD7DMX3WIYyBkFcirOsU1kDbMIXVn+9jXliPK30x8B5BAAD9AgEEADDhFEBVVVW67bbblJmZqdzcXM2dO1d1dXW9tpkxY4aSkpJ6nR5//PGYNg0A6P+cAqimpkYVFRXauXOnPvzwQ3V2dmrWrFlqa2vrtd3ChQvV0NDQc1qxYkVMmwYA9H9Or6Zv2bKl189r1qxRbm6uamtrNX369J7zBw8erPz8/Nh0CAAYkK7oNaCWlhZJ539V8FtvvaURI0Zo4sSJqqys1MmTJy/6O9rb2xWNRnudAAADn/fbsLu7u7VkyRJNmzZNEydO7Dn/oYce0pgxY1RYWKi9e/fqmWeeUV1dnd57770L/p6qqiq9+OKLvm0AAPqppMDzwwWLFi3S3//+d33yyScaNWrURbfbtm2bZs6cqf3792vcuHHnXd7e3q729vaen6PRqIqKilRfX6+srKw+95Oenu52BeT/ORY+B3RWWJ8V8e3Ph8/dwefYS/TPAfkce2Hdton0OZZYCfMY91k/12MvGo2qoKBALS0tl3wc93oGtHjxYm3evFnbt2+/ZPhIUklJiSRdNIAikYgikYhPGwCAfswpgIIg0JNPPqkNGzaourpaxcXFl63Zs2ePJKmgoMCrQQDAwOQUQBUVFVq7dq02bdqkzMxMNTY2SpKys7OVkZGhAwcOaO3atfrxj3+s4cOHa+/evVq6dKmmT5+uSZMmxeUKAAD6J6cAWrVqlaSzHzb9/1avXq0FCxYoPT1dH330kV599VW1tbWpqKhI8+bN07PPPhuzhgEAA4Pzf8FdSlFRkWpqaq6oIQDA1WHATMPu6OhwrvF595KvRJ4c7fuuIp93Zfm82yfMtfPpL5Hf0RbmlHifKdA+t22Y7wb0uU4D8X4RL/3/GgAA+iUCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmEnYYaXJystOwvTAHQvrUhfUVx2HyGdTosw5hfl1xWMMnffbjI9G/vjqsdUj0AaZpaWnONT4DmCUpNdX9Yd/1OOrr9jwDAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJhJsFd25mU2trq1Odz9w0n/lLkpSenu5cMxBnwfnwmesW5iw4Hy4zC88JawYazvKdBZfIs+p8Z8FFIhHnGtdj/Nzj9+WuV8IF0LnGJ06caNwJAOBKtLa2Kjs7+6KXJwVhjontg+7ubh05ckSZmZnn/fURjUZVVFSkQ4cOKSsry6hDe6zDWazDWazDWazDWYmwDkEQqLW1VYWFhZd89pRwz4CSk5M1atSoS26TlZV1VR9g57AOZ7EOZ7EOZ7EOZ1mvw6We+ZzDmxAAACYIIACAiX4VQJFIRMuXL/d6F8dAwjqcxTqcxTqcxTqc1Z/WIeHehAAAuDr0q2dAAICBgwACAJgggAAAJgggAICJfhNAK1eu1HXXXadBgwappKRE//znP61bCt0LL7ygpKSkXqcJEyZYtxV327dv11133aXCwkIlJSVp48aNvS4PgkDPP/+8CgoKlJGRobKyMu3bt8+m2Ti63DosWLDgvONjzpw5Ns3GSVVVlW677TZlZmYqNzdXc+fOVV1dXa9tTp8+rYqKCg0fPlxDhw7VvHnz1NTUZNRxfPRlHWbMmHHe8fD4448bdXxh/SKA1q1bp2XLlmn58uX67LPPNHnyZM2ePVtHjx61bi10N998sxoaGnpOn3zyiXVLcdfW1qbJkydr5cqVF7x8xYoVeu211/TGG29o165dGjJkiGbPnq3Tp0+H3Gl8XW4dJGnOnDm9jo+33347xA7jr6amRhUVFdq5c6c+/PBDdXZ2atasWWpra+vZZunSpXr//fe1fv161dTU6MiRI7r33nsNu469vqyDJC1cuLDX8bBixQqjji8i6AemTp0aVFRU9Pzc1dUVFBYWBlVVVYZdhW/58uXB5MmTrdswJSnYsGFDz8/d3d1Bfn5+8PLLL/ec19zcHEQikeDtt9826DAc316HIAiC+fPnB3fffbdJP1aOHj0aSApqamqCIDh726elpQXr16/v2eZf//pXICnYsWOHVZtx9+11CIIg+OEPfxj89Kc/tWuqDxL+GVBHR4dqa2tVVlbWc15ycrLKysq0Y8cOw85s7Nu3T4WFhRo7dqwefvhhHTx40LolU/X19WpsbOx1fGRnZ6ukpOSqPD6qq6uVm5ur8ePHa9GiRTp+/Lh1S3HV0tIiScrJyZEk1dbWqrOzs9fxMGHCBI0ePXpAHw/fXodz3nrrLY0YMUITJ05UZWWlTp48adHeRSXcMNJv+/rrr9XV1aW8vLxe5+fl5emrr74y6spGSUmJ1qxZo/Hjx6uhoUEvvvii7rjjDn3xxRfKzMy0bs9EY2OjJF3w+Dh32dVizpw5uvfee1VcXKwDBw7oF7/4hcrLy7Vjxw6v76NKdN3d3VqyZImmTZvW8/UtjY2NSk9P17Bhw3ptO5CPhwutgyQ99NBDGjNmjAoLC7V3714988wzqqur03vvvWfYbW8JH0D4n/Ly8p5/T5o0SSUlJRozZozeffddPfroo4adIRE88MADPf++5ZZbNGnSJI0bN07V1dWaOXOmYWfxUVFRoS+++OKqeB30Ui62Do899ljPv2+55RYVFBRo5syZOnDggMaNGxd2mxeU8P8FN2LECKWkpJz3Lpampibl5+cbdZUYhg0bphtvvFH79++3bsXMuWOA4+N8Y8eO1YgRIwbk8bF48WJt3rxZH3/8ca+vb8nPz1dHR4eam5t7bT9Qj4eLrcOFlJSUSFJCHQ8JH0Dp6emaMmWKtm7d2nNed3e3tm7dqtLSUsPO7J04cUIHDhxQQUGBdStmiouLlZ+f3+v4iEaj2rVr11V/fBw+fFjHjx8fUMdHEARavHixNmzYoG3btqm4uLjX5VOmTFFaWlqv46Gurk4HDx4cUMfD5dbhQvbs2SNJiXU8WL8Loi/eeeedIBKJBGvWrAm+/PLL4LHHHguGDRsWNDY2WrcWqp/97GdBdXV1UF9fH/zjH/8IysrKghEjRgRHjx61bi2uWltbg88//zz4/PPPA0nBK6+8Enz++efBf/7znyAIguA3v/lNMGzYsGDTpk3B3r17g7vvvjsoLi4OTp06Zdx5bF1qHVpbW4Onnnoq2LFjR1BfXx989NFHwfe+973ghhtuCE6fPm3deswsWrQoyM7ODqqrq4OGhoae08mTJ3u2efzxx4PRo0cH27ZtC3bv3h2UlpYGpaWlhl3H3uXWYf/+/cEvf/nLYPfu3UF9fX2wadOmYOzYscH06dONO++tXwRQEATB66+/HowePTpIT08Ppk6dGuzcudO6pdDdf//9QUFBQZCenh5ce+21wf333x/s37/fuq24+/jjjwNJ553mz58fBMHZt2I/99xzQV5eXhCJRIKZM2cGdXV1tk3HwaXW4eTJk8GsWbOCkSNHBmlpacGYMWOChQsXDrg/0i50/SUFq1ev7tnm1KlTwRNPPBFcc801weDBg4N77rknaGhosGs6Di63DgcPHgymT58e5OTkBJFIJLj++uuDn//850FLS4tt49/C1zEAAEwk/GtAAICBiQACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgIn/A2fhrQBrxDSQAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 98ms/step\n",
            "Predicted Label: 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IdyvfAVmkdVJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}